{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transferring images from the Postgres DB into the Digital Ocean Space\n",
    "\n",
    "edit: this ends up being throttled somehow (ISP issues?). Deprecating this notebook in favor of getting the images from a database dump in the next notebook.\n",
    "\n",
    "Here's what we need to do to transfer over the raw image data so it's no longer in the database.\n",
    "\n",
    "1. Determine that the size of the DO Space we've chosen will be big enough to last a long time. What is the current size of the images in the DB? How fast do we expect the space usage to grow, given reasonable assumptions about how many keywords we're using?\n",
    "2. Get a list of all images we're going to query for\n",
    "3. Update the API so that saving all new images will save to the DO Space rather than the database\n",
    "4. Get the image binary data of an image, save it with the new API image save endpoint, then check that any query that includes that image metadata links to the new DO Space image URL\n",
    "5. run for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. size of Space\n",
    "\n",
    "I'll check back on this after transfering over all the images from the DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. list of all images to query\n",
    "\n",
    "I have node running the server.js file in the api folder on my test server, which has the same database as prod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# base = 'http://159.89.80.47'\n",
    "base = 'http://api.firewallcafe.com'\n",
    "folder = 'images'\n",
    "\n",
    "os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = requests.get(base + '/images?page_size=200&page=2').json()\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 626520,\n",
       " 'image_search_engine': 'baidu',\n",
       " 'image_href': 'https://firewall-cafe-space.nyc3.digitaloceanspaces.com/images/hashed/de2ece85a092791e.jpg',\n",
       " 'image_rank': '1',\n",
       " 'image_mime_type': None,\n",
       " 'wordpress_attachment_post_id': None,\n",
       " 'wordpress_attachment_file_path': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. update API to save images to DO\n",
    "\n",
    "I have this running on a branch of my dovinmu fork of firewall cafe's codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~~4. get binary and save to API~~ setup for putting images on DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "# Image.open(StringIO(img[0]['image_data']['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sidenote: I just discovered that Postman can generate code for a given request. My life could have been so much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imagehash\n",
    "\n",
    "def hash_image(img):\n",
    "    return imagehash.phash(fname)\n",
    "\n",
    "def image_fname(url):\n",
    "#     print(url)\n",
    "    def reduce(char):\n",
    "        return char if char not in set('.`\\'\"()[]{}\\\\;&%@,-=+$:/<>~ ?') else '_'\n",
    "    if '://' in url: url = url.split('://')[1]\n",
    "    if url[-4:] == '.jpg': url = url[:-4]\n",
    "    url = ''.join([reduce(char) for char in url])\n",
    "    if len(url) > 150:\n",
    "        url = url[:150] + '__' + str(random.randint(100,1000))\n",
    "    return url\n",
    "image_fname(\"https://google.com/test-worked.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. run for all images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Digital Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('digital-ocean-config.json') as f:\n",
    "    config = json.loads(f.read())\n",
    "\n",
    "import boto3\n",
    "\n",
    "bucket_endpoint = f'https://{config[\"bucket\"]}.{config[\"region\"]}.digitaloceanspaces.com'\n",
    "# Initialize a session using DigitalOcean Spaces.\n",
    "session = boto3.session.Session()\n",
    "client = session.client('s3',\n",
    "    region_name = config['region'],\n",
    "    endpoint_url = f'https://{config[\"region\"]}.digitaloceanspaces.com',\n",
    "    aws_access_key_id = config['access_key_id'],\n",
    "    aws_secret_access_key = config['secret_access_key'])\n",
    "transfer = boto3.s3.transfer.S3Transfer(client)\n",
    "\n",
    "def write_image_to_do(fname, new_fname):\n",
    "    transfer.upload_file(fname, config['bucket'], new_fname)\n",
    "    # make that file public\n",
    "    r = client.put_object_acl(ACL='public-read', Bucket=config['bucket'], Key=new_fname)\n",
    "    if r['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
    "        return bucket_endpoint + '/' + new_fname\n",
    "    raise Exception(\"error from DO:\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "failures = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is insanely inefficient code which gets the images from their original URLs and puts them on DO, but only needs to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "import time\n",
    "import io\n",
    "\n",
    "class Storage:\n",
    "    def __init__(self):\n",
    "        self.start = time.time()\n",
    "        self._lock = threading.Lock()\n",
    "        self.failures = {}\n",
    "        self.errors = {}\n",
    "        self.count = 0\n",
    "        \n",
    "    def add_failure(self, image_id, url, e):\n",
    "        with self._lock:\n",
    "            self.failures[image_id] = url\n",
    "            self.errors[image_id] = e\n",
    "\n",
    "    def increment_count(self):\n",
    "        with self._lock:\n",
    "            self.count += 1\n",
    "    \n",
    "    def print_status(self):\n",
    "        with self._lock:\n",
    "            print(f\"processing {self.count} took {round((time.time()-self.start)/60, 1)} minutes. \\\n",
    "{round(100*(len(self.failures)/self.count), 1)}% failure rate & {len(self.failures)} failures, {round((time.time()-self.start)/self.count, 1)} s per\")\n",
    "\n",
    "storage = Storage()\n",
    "def worker():\n",
    "    while True:\n",
    "        image_id, url = q.get()\n",
    "        if url is None:\n",
    "            print('x', end=' ')\n",
    "            break\n",
    "        \n",
    "        storage.increment_count()\n",
    "#         fname = image_fname(url)\n",
    "        \n",
    "        # save image in temp folder\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "        except Exception as e:\n",
    "            storage.add_failure(image_id, url, e)\n",
    "            continue\n",
    "        try:\n",
    "            in_memory_file = io.BytesIO(r.content)\n",
    "            im = Image.open(in_memory_file)\n",
    "            fname = hash_image(im)\n",
    "        except Exception as e:\n",
    "            storage.add_failure(image_id, url, e)\n",
    "            continue\n",
    "#         print(os.pwd(), fname, ext)\n",
    "        try:\n",
    "            ext = '.jpg'\n",
    "            im.save(folder + '/' + fname + ext)\n",
    "        except:\n",
    "            try:\n",
    "                ext = '.' + im.format.lower()\n",
    "                im.save(folder + '/' + fname + ext)\n",
    "            except Exception as e:\n",
    "                storage.add_failure(image_id, url, e)\n",
    "        if random.randint(0,100) == 42:\n",
    "            storage.print_status()\n",
    "        q.task_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cache the /image responses so we don't hammer that poor DO Droplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_pages = []\n",
    "# for page_num in range(0, 201):\n",
    "#     ts = time.time()\n",
    "#     j = requests.get(base + '/images?page_size=1000&page=' + str(page_num)).json()\n",
    "#     image_pages.append(j)\n",
    "#     print(page_num, round(time.time()-ts), len(j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('image_pages.json', 'w') as f:\n",
    "#     f.write(json.dumps(image_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image_pages.json', 'r') as f:\n",
    "    image_pages = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done with /image queries\n",
      "telling threads to stop\n",
      "waiting\n",
      "processing 72 took 0.2 minutes. 1.4% failure rate & 1 failures, 0.2 s per\n",
      "processing 117 took 0.3 minutes. 6.0% failure rate & 7 failures, 0.1 s per\n",
      "processing 296 took 0.6 minutes. 10.8% failure rate & 32 failures, 0.1 s per\n",
      "processing 446 took 1.1 minutes. 11.9% failure rate & 53 failures, 0.1 s per\n",
      "processing 701 took 1.5 minutes. 11.3% failure rate & 79 failures, 0.1 s per\n",
      "processing 740 took 1.6 minutes. 11.5% failure rate & 85 failures, 0.1 s per\n",
      "processing 769 took 1.6 minutes. 11.3% failure rate & 87 failures, 0.1 s per\n",
      "processing 782 took 1.7 minutes. 11.4% failure rate & 89 failures, 0.1 s per\n",
      "x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x "
     ]
    }
   ],
   "source": [
    "num_worker_threads = 50\n",
    "\n",
    "# set up threading and queueing infra\n",
    "q = queue.Queue()\n",
    "threads = []\n",
    "for i in range(num_worker_threads):\n",
    "    t = threading.Thread(target=worker)\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# iterating over all images in DB\n",
    "for j in image_pages:\n",
    "#     print(\"skipping image downloading\")\n",
    "#     break\n",
    "    for img in j:\n",
    "        count += 1\n",
    "        # make filename from url\n",
    "        if img['image_href'] is not None:\n",
    "            url = img['image_href']\n",
    "        elif img['wordpress_attachment_file_path'] is not None:\n",
    "            url = 'http://firewallcafe.com' + img['wordpress_attachment_file_path']\n",
    "        else:\n",
    "            continue\n",
    "        # put the url into the queue for the workers\n",
    "        q.put((img['image_id'], url))\n",
    "    break\n",
    "        # upload to DO manually\n",
    "#         url = write_image_to_do('temp/img'+ext, 'images/url_based/'+fname+ext)\n",
    "print(\"\\ndone with /image queries\\ntelling threads to stop\")\n",
    "for i in range(num_worker_threads):\n",
    "    q.put((None,None))\n",
    "print('waiting')\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.print_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all image URLs in the list against their corresponding filenames in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pages[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = image_fname(image_pages[10][5]['image_href'])\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = set(os.listdir(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{fn}.jpg' in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_count = 0\n",
    "missing = []\n",
    "for image_page in image_pages:\n",
    "    for image in image_page:\n",
    "        fn = image_fname(image['image_href'])\n",
    "        if f'{fn}.jpg' in images:\n",
    "            found_count += 1\n",
    "        else:\n",
    "            missing.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_jpgs = [fname for fname in images if fname[-4:] != '.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_jpgs)/len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(100*found_count/(found_count+len(missing)), 2), '% found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
